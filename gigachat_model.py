import os
from datetime import datetime
import uuid
import json
import time

import litellm
from litellm import CustomLLM, completion, get_llm_provider, ModelResponse, Choices, Message, Usage
from gigachat import GigaChat
from pprint import pprint

model_name = "GigaChat:2.0.28.02"
base_url = "https://gigachat.ift.sberdevices.ru/v1"


# class GigaChatUserLLM(CustomLLM):
#     def __init__(self):
#         super().__init__()
#         self.model_name = model_name  # HARD
#         kwargs_giga = dict(
#             model=self.model_name,
#             base_url=base_url,
#             credentials=os.environ.get("GIGACHAT_CREDENTIALS", None),
#             access_token=os.getenv("GIGACHAT_TOKEN"),
#             scope=os.environ.get("GIGACHAT_SCOPE", "GIGACHAT_API_CORP"),
#             verify_ssl_certs=False,
#             profanity_check=False,
#             timeout=600,
#         )
#         self.llm = GigaChat(**kwargs_giga)

#     def completion(self, *args, **kwargs) -> litellm.ModelResponse:
#         # print("User")
#         messages = kwargs.get("messages", [])
#         i, max_retries = 0, 20
#         while i < max_retries:
#             try:
#                 response = self.llm.chat({"messages": messages})
#                 break
#             except Exception as e:
#                 print(type(e), e)
#                 time.sleep(5)
#             i += 1

#         message = Message(
#             role=response.choices[-1].message.role,
#             content=response.choices[-1].message.content,
#             provider_specific_fields=None
#         )

#         model_response = ModelResponse(
#             id=response.x_headers["x-request-id"],
#             created=response.created,
#             model=response.model,
#             object=response.object_,
#             choices=[Choices(index=response.choices[-1].index, message=message, finish_reason=response.choices[-1].finish_reason)],
#             usage=Usage(
#                 prompt_tokens=response.usage.prompt_tokens,
#                 completion_tokens=response.usage.completion_tokens,
#                 total_tokens=response.usage.total_tokens,
#             ),
#         )
#         return model_response


class GigaChatCustomLLM(CustomLLM):
    def __init__(self):
        super().__init__()
        self.model_name = model_name  # HARD
        kwargs_giga = dict(
            model=self.model_name,
            base_url=base_url,
            credentials=os.environ.get("GIGACHAT_CREDENTIALS", None),
            access_token=os.getenv("GIGACHAT_TOKEN"),
            scope=os.environ.get("GIGACHAT_SCOPE", "GIGACHAT_API_CORP"),
            verify_ssl_certs=False,
            profanity_check=False,
            timeout=600,
        )
        self.llm = GigaChat(**kwargs_giga)

    def completion(self, *args, **kwargs) -> litellm.ModelResponse:
        # print("NoUser")
        messages = kwargs.get("messages", [])
        functions = kwargs.get("optional_params", {}).get("tools", [])

        for i, m in enumerate(messages):  # –∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä—É–µ–º messages –¥–ª—è –≥–∏–≥–∏

            if "tool_calls" in m:  # –º–µ–Ω—è–µ–º tool_calls –Ω–∞ function_call –∏ –∑–∞–ø–∏—Å—ã–≤–∞–µ–º –≤ –Ω–µ–≥–æ –∑–∞–ø—Ä–æ—Å –∫ —Ñ—É–Ω–∫—Ü–∏–∏ –∏ –æ—Ç–≤–µ—Ç –æ—Ç —Ñ—É–Ω–∫—Ü–∏–∏
                tool_calls = messages[i].pop("tool_calls")

                tc_func = tool_calls[0].get("function")
                if isinstance(tc_func.get("arguments"), str):
                    try:
                        tc_func["arguments"] = json.loads(tc_func.get("arguments"))
                    except (json.JSONDecodeError, TypeError):
                        tc_func["arguments"] = tc_func.get("arguments")

                messages[i] = {
                    "function_call": tc_func,
                    "functions_state_id": tool_calls[0].get("id"),
                    "content": messages[i+1]["content"],
                    "role": messages[i]["role"]
                }

            if m.get("role") == "tool":  # –¥–æ–±–∞–≤–ª—è–µ–º –æ—Ç–≤–µ—Ç —Ñ—É–Ω–∫—Ü–∏–∏ –≤ –∏—Å—Ç–æ—Ä–∏—é —á–∞—Ç–∞
                if isinstance(m["content"], str):  # –ø—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —É —Ñ—É–Ω–∫—Ü–∏–∏ –æ—Ç–≤–µ—Ç (—Å—Ç—Ä–æ–∫–∞ —Å–æ —Å–ª–æ–≤–∞—Ä–µ–º –≤–Ω—É—Ç—Ä–∏, –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏ –∏–ª–∏ –ø—Ä–æ—Å—Ç–æ —Å—Ç—Ä–æ–∫–∏ –≥–∏–≥–∞ –Ω–µ –≤—Å–ø—Ä–∏–Ω–∏–º–∞–µ—Ç)
                    try:
                        m_content = json.loads(m["content"])
                        m_content = m["content"]
                    except (json.JSONDecodeError, TypeError):
                        m_content = json.dumps({"result": m["content"]})

                messages[i] = {
                    "role": "function",
                    "content": m_content,
                    "name": messages[i]["name"],
                }


        function_call_json  = {
            "messages": messages,
            "function_call": "auto",
            "functions": [func["function"] for func in functions],
        }
        i, max_retries = 0, 5
        while i < max_retries:
            try:
                response = self.llm.chat(function_call_json)
                break
            except Exception as e:
                print(type(e), e)
                time.sleep(5)
            i += 1

        fc = response.choices[-1].message.function_call
        message = Message(
            role=response.choices[-1].message.role,
            content=response.choices[-1].message.content,
            tool_calls=fc if fc is None else [{"function": {"arguments": json.dumps(fc.arguments), "name": fc.name}}],
            provider_specific_fields=None
        )

        model_response = ModelResponse(
            id=response.x_headers["x-request-id"],
            created=response.created,
            model=response.model,
            object=response.object_,
            choices=[Choices(index=response.choices[-1].index, message=message, finish_reason=response.choices[-1].finish_reason)],
            usage=Usage(
                prompt_tokens=response.usage.prompt_tokens,
                completion_tokens=response.usage.completion_tokens,
                total_tokens=response.usage.total_tokens,
            ),
        )

        return model_response


gigachat_custom_llm = GigaChatCustomLLM()
# gigachat_user_llm = GigaChatUserLLM()

litellm.custom_provider_map = [ # üëà KEY STEP - REGISTER HANDLER
    # {"provider": "gigachat_user", "custom_handler": gigachat_user_llm},
    {"provider": "gigachat", "custom_handler": gigachat_custom_llm}
]


# resp = completion(
#     model=f"gigachat_user/{model_name}",
#     messages=[{"role": "user", "content": "Hello world!"}],
#     # –æ—Ç–≤–µ—á–∞–µ—Ç –∑–∞ —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—é —Å—Ç–æ–∏–º–æ—Å—Ç–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –º–æ–¥–µ–ª–∏, –µ—Å–ª–∏ –µ—â–µ input_cost_per_token –∏ output_cost_per_token
#     # –±–µ–∑ –Ω–µ–≥–æ –ø–æ –¥–µ—Ñ–æ–ª—Ç—É res._hidden_params["response_cost"] = None (res = completion(...)), –∏ –æ—à–∏–±–∫–∞ "couldnt add None and 0.0"
#     input_cost_per_second=0.0
# )
resp = completion(
    model=f"gigachat/{model_name}",
    messages=[{"role": "user", "content": "Hello world!"}],
    # –æ—Ç–≤–µ—á–∞–µ—Ç –∑–∞ —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—é —Å—Ç–æ–∏–º–æ—Å—Ç–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –º–æ–¥–µ–ª–∏, –µ—Å–ª–∏ –µ—â–µ input_cost_per_token –∏ output_cost_per_token
    # –±–µ–∑ –Ω–µ–≥–æ –ø–æ –¥–µ—Ñ–æ–ª—Ç—É res._hidden_params["response_cost"] = None (res = completion(...)), –∏ –æ—à–∏–±–∫–∞ "couldnt add None and 0.0"
    input_cost_per_second=0.0
)
